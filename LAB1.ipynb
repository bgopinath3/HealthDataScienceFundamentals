{"cells":[{"cell_type":"markdown","source":["# Lab 1\n\nThis very first lab will introduce to some PyTorch basics including Tensors, Loss, and Autograd. Hopefully, we will start to get familar with PyTorch. In the end, we will implement a linear regression model from sratch with some synthetic data.\n\nTable of Contents:\n- Tensors\n- Loss\n- Autograd\n- Assignment\n\nSome contents of this lab are adapted from [Dive into Deep Learning](https://d2l.ai) and [Official PyTorch Tutorials](https://pytorch.org/tutorials/)."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-8653d83277fb8418","locked":true,"solution":false,"checksum":"c9f943bc6d17f5c41bf78d0fbd8204ab","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c8081da-8e7e-4bc2-9a62-fa37793f3497"}}},{"cell_type":"code","source":["import os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.845064Z","start_time":"2021-11-09T19:59:52.299637Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97ed05ee-de65-4416-8284-d2104216f706"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-7523865a465c9b1e","locked":true,"solution":false,"checksum":"d3642e7fe74ecb8701a63240216578ce","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# set seed\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.851501Z","start_time":"2021-11-09T19:59:52.847236Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f090ab0f-a3eb-4994-9e93-cefefcbf7151"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-825b96ce06875360","locked":true,"solution":false,"checksum":"aa13dd5c807dbeb0e92cebc3125b9092","grade":false,"cell_type":"code"},"editable":false},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 1. Tensors\n\nTensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n\nTensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. Tensors are also optimized for automatic differentiation (we’ll see more about that later in the Autograd section)."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-7b7bbb08dff3040d","locked":true,"solution":false,"checksum":"e37e8000c736b9a9406f0d119ff7f3a7","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59bdb8ce-f45a-4e9f-83ab-4a3e3906c9f4"}}},{"cell_type":"markdown","source":["### 1.1 Initializing a Tensor\n\nTensors can be initialized in various ways. Take a look at the following examples:"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-b03b01d3bd61bc0f","locked":true,"solution":false,"checksum":"8a4a90005ecf60dd50e62ea7de665f9a","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18d92592-a71f-4be3-97c1-abd39c677578"}}},{"cell_type":"markdown","source":["**Directly from data**\n\nTensors can be created directly from data. The data type is automatically inferred."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-2583c6a26873f427","locked":true,"solution":false,"checksum":"77458c2ce63f29f0d1ad965bd8886bdb","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0830760e-06bb-4cd7-9673-359b85bab670"}}},{"cell_type":"code","source":["data = [[1, 2],[3, 4]]\nx_data = torch.tensor(data)\nx_data"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.858154Z","start_time":"2021-11-09T19:59:52.853403Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a8db75b4-004b-4f22-92bd-da2f27d8d036"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-741b5efbb2c5f945","locked":true,"solution":false,"checksum":"75ee8eefcb5a96b60d90d2b42b6dbef9","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[3]: tensor([[1, 2],\n        [3, 4]])","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[3]: tensor([[1, 2],\n        [3, 4]])"]}}],"execution_count":0},{"cell_type":"markdown","source":["**From a NumPy array**\n\nTensors can be created from NumPy arrays (and vice versa)."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-a51593eb71551154","locked":true,"solution":false,"checksum":"654228ea3cb6365f53bbead1dd9872b9","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04062436-2ad7-4e9c-8b76-b5e7c05959f2"}}},{"cell_type":"code","source":["np_array = np.array(data)\nx_np = torch.from_numpy(np_array)\nx_np"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.863349Z","start_time":"2021-11-09T19:59:52.859841Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7689eb75-d7bf-4cf4-9ab7-e8603eff8a82"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-b2b7443d0480311c","locked":true,"solution":false,"checksum":"74779b8dd201e86c3c29040d89e07ad3","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[4]: tensor([[1, 2],\n        [3, 4]])","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[4]: tensor([[1, 2],\n        [3, 4]])"]}}],"execution_count":0},{"cell_type":"markdown","source":["**From another tensor:**\n\nThe new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-8ee52e294863edd9","locked":true,"solution":false,"checksum":"7efc6ab13e7bb7ebef435ad392769a0d","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55be7dd1-f6fd-42ea-9479-5144849ace0c"}}},{"cell_type":"code","source":["x_ones = torch.ones_like(x_data) # retains the properties of x_data\nprint(f\"Ones Tensor: \\n {x_ones} \\n\")\n\nx_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\nprint(f\"Random Tensor: \\n {x_rand} \\n\")"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.869010Z","start_time":"2021-11-09T19:59:52.864867Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a85b752d-5359-44bf-9d9b-496f1da59f6f"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-ceed6cc164f03815","locked":true,"solution":false,"checksum":"ee6b4d83b94c4d3969cb7d973229b505","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Ones Tensor: \n tensor([[1, 1],\n        [1, 1]]) \n\nRandom Tensor: \n tensor([[0.8823, 0.9150],\n        [0.3829, 0.9593]]) \n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Ones Tensor: \n tensor([[1, 1],\n        [1, 1]]) \n\nRandom Tensor: \n tensor([[0.8823, 0.9150],\n        [0.3829, 0.9593]]) \n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**With random or constant values:**\n\n``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-4671fa03f3944139","locked":true,"solution":false,"checksum":"43bb0a3f9c2770d1984d84f42a75f907","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a75bfccc-9970-49fb-bdd9-b0ac553e8c16"}}},{"cell_type":"code","source":["shape = (2,3,)\nrand_tensor = torch.rand(shape)\nones_tensor = torch.ones(shape)\nzeros_tensor = torch.zeros(shape)\n\nprint(f\"Random Tensor: \\n {rand_tensor} \\n\")\nprint(f\"Ones Tensor: \\n {ones_tensor} \\n\")\nprint(f\"Zeros Tensor: \\n {zeros_tensor}\")"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.876523Z","start_time":"2021-11-09T19:59:52.871788Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83d98e64-8b4d-40b3-863a-c8b4e47f4729"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-d85438a27666f252","locked":true,"solution":false,"checksum":"27f971907aa50b901fa91edd9c576761","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Random Tensor: \n tensor([[0.3904, 0.6009, 0.2566],\n        [0.7936, 0.9408, 0.1332]]) \n\nOnes Tensor: \n tensor([[1., 1., 1.],\n        [1., 1., 1.]]) \n\nZeros Tensor: \n tensor([[0., 0., 0.],\n        [0., 0., 0.]])\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Random Tensor: \n tensor([[0.3904, 0.6009, 0.2566],\n        [0.7936, 0.9408, 0.1332]]) \n\nOnes Tensor: \n tensor([[1., 1., 1.],\n        [1., 1., 1.]]) \n\nZeros Tensor: \n tensor([[0., 0., 0.],\n        [0., 0., 0.]])\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 1.2 Attributes of a Tensor\n\nTensor attributes describe their shape, datatype, and the device on which they are stored."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-c8f38367d33a874e","locked":true,"solution":false,"checksum":"b5d46abd7766af09043a3bc674fd153b","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5121d48-29db-47ba-aeee-70426695af3d"}}},{"cell_type":"code","source":["tensor = torch.rand(3,4)\n\nprint(f\"Shape of tensor: {tensor.shape}\")\nprint(f\"Datatype of tensor: {tensor.dtype}\")\nprint(f\"Device tensor is stored on: {tensor.device}\")"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.881522Z","start_time":"2021-11-09T19:59:52.878755Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a55de9e9-574b-4202-ba9a-ec5d3082c270"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-0f572ccb4f2eed6d","locked":true,"solution":false,"checksum":"a1de096b26be8502d768cf0112e683a0","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Shape of tensor: torch.Size([3, 4])\nDatatype of tensor: torch.float32\nDevice tensor is stored on: cpu\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Shape of tensor: torch.Size([3, 4])\nDatatype of tensor: torch.float32\nDevice tensor is stored on: cpu\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 1.3 Operations on Tensors\n\nOver 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, \nindexing, slicing), sampling and more are\ncomprehensively described [here](https://pytorch.org/docs/stable/torch.html)."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-5bc51b213e3495d9","locked":true,"solution":false,"checksum":"abe60a975331fdb7d519d53ef968c668","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9aa6198a-8081-4212-ba67-1bf14bf1f170"}}},{"cell_type":"markdown","source":["Let us try out some of the operations from the list. They are pretty similar to the NumPy API."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-e96ca63d0ccacaf4","locked":true,"solution":false,"checksum":"0115fa9eefb5d1d11440455f5460babe","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a48a381-2e52-4278-a30e-43670ca53507"}}},{"cell_type":"markdown","source":["**Standard numpy-like indexing and slicing:**"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-79f659ce1e13fda7","locked":true,"solution":false,"checksum":"4dc3b4f6bb8c31e810c70a2ee180c89b","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9dc090d1-472c-4afa-93c5-ce58a7a2b1b3"}}},{"cell_type":"code","source":["tensor = torch.arange(12).reshape(3, 4).float()\nprint(tensor)\nprint('First row: ',tensor[0])\nprint('First column: ', tensor[:, 0])\nprint('Last column:', tensor[:, -1])"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.889292Z","start_time":"2021-11-09T19:59:52.883071Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e9a1d9e-cacc-49ec-b463-d88f2ef91485"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-68254433d58dfef9","locked":true,"solution":false,"checksum":"27670eb419578cd89154f9d8d942fd13","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.]])\nFirst row:  tensor([0., 1., 2., 3.])\nFirst column:  tensor([0., 4., 8.])\nLast column: tensor([ 3.,  7., 11.])\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.]])\nFirst row:  tensor([0., 1., 2., 3.])\nFirst column:  tensor([0., 4., 8.])\nLast column: tensor([ 3.,  7., 11.])\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Joining tensors** \n\nYou can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\nSee also [`torch.stack`](https://pytorch.org/docs/stable/generated/torch.stack.html),\nanother tensor joining op that is subtly different from ``torch.cat``."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-07fe46d6a751454b","locked":true,"solution":false,"checksum":"9bf20b4a386a1ede2ba268a8c61ab940","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd6b9006-aa66-4f72-b101-b0e4c6ec3c5f"}}},{"cell_type":"code","source":["t1 = torch.cat([tensor, tensor, tensor], dim=1)\nprint(t1)"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.894432Z","start_time":"2021-11-09T19:59:52.890861Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18ac0385-17e3-41c8-a46d-5002ffa07bcf"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-8436764a1dd93dc7","locked":true,"solution":false,"checksum":"804fe5871c972fef2865361d99b3217c","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"tensor([[ 0.,  1.,  2.,  3.,  0.,  1.,  2.,  3.,  0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.,  4.,  5.,  6.,  7.,  4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.,  8.,  9., 10., 11.,  8.,  9., 10., 11.]])\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["tensor([[ 0.,  1.,  2.,  3.,  0.,  1.,  2.,  3.,  0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.,  4.,  5.,  6.,  7.,  4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.,  8.,  9., 10., 11.,  8.,  9., 10., 11.]])\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Arithmetic operations**"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-70ab95dd8071897a","locked":true,"solution":false,"checksum":"b12186a7d48bc1a79d835fb1c1e5f97e","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"286e8ec5-096d-43ef-b771-c723d02a8057"}}},{"cell_type":"code","source":["# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\ny1 = tensor @ tensor.T\nprint(y1)\ny2 = tensor.matmul(tensor.T)\nprint(y2)\ny3 = torch.rand_like(tensor)\ntorch.matmul(tensor, tensor.T, out=y3)\nprint(y3)"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.902039Z","start_time":"2021-11-09T19:59:52.896106Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4a4778b-c760-46e8-9f9d-9c5ab532367d"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-17ade2df712e21e6","locked":true,"solution":false,"checksum":"c63e7fa1111d6e43fe822182db67f8ec","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"tensor([[ 14.,  38.,  62.],\n        [ 38., 126., 214.],\n        [ 62., 214., 366.]])\ntensor([[ 14.,  38.,  62.],\n        [ 38., 126., 214.],\n        [ 62., 214., 366.]])\ntensor([[ 14.,  38.,  62.],\n        [ 38., 126., 214.],\n        [ 62., 214., 366.]])\n<command-320279718370882>:7: UserWarning: An output with one or more elements was resized since it had shape [3, 4], which does not match the required output shape [3, 3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n  torch.matmul(tensor, tensor.T, out=y3)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["tensor([[ 14.,  38.,  62.],\n        [ 38., 126., 214.],\n        [ 62., 214., 366.]])\ntensor([[ 14.,  38.,  62.],\n        [ 38., 126., 214.],\n        [ 62., 214., 366.]])\ntensor([[ 14.,  38.,  62.],\n        [ 38., 126., 214.],\n        [ 62., 214., 366.]])\n<command-320279718370882>:7: UserWarning: An output with one or more elements was resized since it had shape [3, 4], which does not match the required output shape [3, 3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:24.)\n  torch.matmul(tensor, tensor.T, out=y3)\n"]}}],"execution_count":0},{"cell_type":"code","source":["# This computes the element-wise product. z1, z2, z3 will have the same value\nz1 = tensor * tensor\nprint(z1)\nz2 = tensor.mul(tensor)\nprint(z2)\nz3 = torch.rand_like(tensor)\ntorch.mul(tensor, tensor, out=z3)\nprint(z3)"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.908790Z","start_time":"2021-11-09T19:59:52.903624Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c46d1215-23a0-464c-9575-2c4be0571da7"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-a119420de324266c","locked":true,"solution":false,"checksum":"6974f540d18fb1e42492acd33b3a9b5c","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"tensor([[  0.,   1.,   4.,   9.],\n        [ 16.,  25.,  36.,  49.],\n        [ 64.,  81., 100., 121.]])\ntensor([[  0.,   1.,   4.,   9.],\n        [ 16.,  25.,  36.,  49.],\n        [ 64.,  81., 100., 121.]])\ntensor([[  0.,   1.,   4.,   9.],\n        [ 16.,  25.,  36.,  49.],\n        [ 64.,  81., 100., 121.]])\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["tensor([[  0.,   1.,   4.,   9.],\n        [ 16.,  25.,  36.,  49.],\n        [ 64.,  81., 100., 121.]])\ntensor([[  0.,   1.,   4.,   9.],\n        [ 16.,  25.,  36.,  49.],\n        [ 64.,  81., 100., 121.]])\ntensor([[  0.,   1.,   4.,   9.],\n        [ 16.,  25.,  36.,  49.],\n        [ 64.,  81., 100., 121.]])\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Single-element tensors** \n\nIf you have a one-element tensor, for example by aggregating all\nvalues of a tensor into one value, you can convert it to a Python\nnumerical value using ``item()``:"],"metadata":{"ExecuteTime":{"end_time":"2021-06-04T10:52:36.043345Z","start_time":"2021-06-04T10:52:36.039305Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d25201a-7568-4f30-a6d9-3498449d9f1e"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-ee43563ec55838ed","locked":true,"solution":false,"checksum":"82040cf6f62c339db1c08cdb9fb7d97c","grade":false,"cell_type":"markdown"},"editable":false}},{"cell_type":"code","source":["agg = tensor.sum()\nagg_item = agg.item()  \nprint(agg_item, type(agg_item))"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:52.912965Z","start_time":"2021-11-09T19:59:52.910269Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0cb83ed-8182-4537-927f-58aa2017cf44"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-d398db15eb46f650","locked":true,"solution":false,"checksum":"e95651812e9d9df69e9b56d0d366efa8","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"66.0 <class 'float'>\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["66.0 <class 'float'>\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 1.4 GPU Acceleration\n\nIf we have NVIDIA GPU(s), we can accelerate computation once we move Tensors onto GPU.\nLet's compare how much GPU can accelerate especially matrix operations.\nWe will do a matrix-matrix multiplication between two 5k-by-5k matrices on both CPU and GPU.\n\nUnfortunately, Coursera does not have a GPU environment. But feel free to try the following snippets on a GPU machine. Ideally, with GPU acceleration, matrix multiplication will be much faster."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-ad4c08ac5cb16f59","locked":true,"solution":false,"checksum":"b648e27cde024b597ebb95528fd89e47","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4fb771e-c654-4eee-9434-359eb367fcab"}}},{"cell_type":"code","source":["mat = torch.rand(5000, 5000)\nmat"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.064705Z","start_time":"2021-11-09T19:59:52.914547Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2433fa5-d3dc-49c7-ba2b-56c431d30bfc"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-4a444edeeb9268a9","locked":true,"solution":false,"checksum":"9e62482cd8575e2e93b0582038b96841","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[13]: tensor([[0.7886, 0.5895, 0.7539,  ..., 0.9313, 0.6453, 0.9844],\n        [0.8312, 0.8682, 0.9359,  ..., 0.4046, 0.9987, 0.8608],\n        [0.1268, 0.2253, 0.1223,  ..., 0.3939, 0.4493, 0.5327],\n        ...,\n        [0.5851, 0.5824, 0.8857,  ..., 0.3165, 0.4845, 0.3896],\n        [0.3348, 0.1535, 0.5840,  ..., 0.0285, 0.7444, 0.5193],\n        [0.4027, 0.7190, 0.3847,  ..., 0.9606, 0.6629, 0.0359]])","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[13]: tensor([[0.7886, 0.5895, 0.7539,  ..., 0.9313, 0.6453, 0.9844],\n        [0.8312, 0.8682, 0.9359,  ..., 0.4046, 0.9987, 0.8608],\n        [0.1268, 0.2253, 0.1223,  ..., 0.3939, 0.4493, 0.5327],\n        ...,\n        [0.5851, 0.5824, 0.8857,  ..., 0.3165, 0.4845, 0.3896],\n        [0.3348, 0.1535, 0.5840,  ..., 0.0285, 0.7444, 0.5193],\n        [0.4027, 0.7190, 0.3847,  ..., 0.9606, 0.6629, 0.0359]])"]}}],"execution_count":0},{"cell_type":"code","source":["%%time\ntorch.mm(mat.t(), mat)"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.619739Z","start_time":"2021-11-09T19:59:53.066447Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"484b5621-e5b1-464c-beeb-c0e0024a83d5"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-3fd0c22a92e541e3","locked":true,"solution":false,"checksum":"4b3a80ee483007acd54cd3b012c53f5f","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"CPU times: user 10 s, sys: 1.61 s, total: 11.6 s\nWall time: 517 ms\nOut[14]: tensor([[1697.6150, 1260.7886, 1260.5798,  ..., 1276.7966, 1265.4301,\n         1273.4854],\n        [1260.7886, 1655.7583, 1247.6844,  ..., 1256.2369, 1263.6820,\n         1263.9419],\n        [1260.5798, 1247.6844, 1658.2700,  ..., 1258.1453, 1267.2045,\n         1274.8801],\n        ...,\n        [1276.7966, 1256.2367, 1258.1453,  ..., 1704.4204, 1270.7224,\n         1275.9523],\n        [1265.4302, 1263.6820, 1267.2046,  ..., 1270.7224, 1686.0026,\n         1272.0712],\n        [1273.4852, 1263.9419, 1274.8801,  ..., 1275.9523, 1272.0712,\n         1699.9994]])","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["CPU times: user 10 s, sys: 1.61 s, total: 11.6 s\nWall time: 517 ms\nOut[14]: tensor([[1697.6150, 1260.7886, 1260.5798,  ..., 1276.7966, 1265.4301,\n         1273.4854],\n        [1260.7886, 1655.7583, 1247.6844,  ..., 1256.2369, 1263.6820,\n         1263.9419],\n        [1260.5798, 1247.6844, 1658.2700,  ..., 1258.1453, 1267.2045,\n         1274.8801],\n        ...,\n        [1276.7966, 1256.2367, 1258.1453,  ..., 1704.4204, 1270.7224,\n         1275.9523],\n        [1265.4302, 1263.6820, 1267.2046,  ..., 1270.7224, 1686.0026,\n         1272.0712],\n        [1273.4852, 1263.9419, 1274.8801,  ..., 1275.9523, 1272.0712,\n         1699.9994]])"]}}],"execution_count":0},{"cell_type":"code","source":["%%time\nif torch.cuda.is_available():\n    mat = mat.cuda()\n    torch.mm(mat.t(), mat)\nelse:\n    print('GPU is not available!')"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.624524Z","start_time":"2021-11-09T19:59:53.621511Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e36430d-bdf0-4d2d-8684-3e5384184680"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-cba286fd4075d893","locked":true,"solution":false,"checksum":"b4763761e1069ee61e30ea187629ff02","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"CPU times: user 1.5 s, sys: 1.16 s, total: 2.67 s\nWall time: 2.67 s\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["CPU times: user 1.5 s, sys: 1.16 s, total: 2.67 s\nWall time: 2.67 s\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Exercise 1 [10 points]\n\nImplement the Sigmoid function on your own.\n\n$$\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$$\n\nNote that you should not use existing PyTorch implementation.\n\nHint: try `torch.exp()`."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-76b1139eccd0ed58","locked":true,"solution":false,"checksum":"dc18412bf74237429ce30f815793755b","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6906e27d-5bcd-4404-8c3c-359658361a96"}}},{"cell_type":"code","source":["def sigmoid(x):\n    # your code here\n    return 1 / (1+torch.exp(-x))\n    #raise NotImplementedError"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.628821Z","start_time":"2021-11-09T19:59:53.626556Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc925ca6-dac8-41c6-96cf-00e7c4ea6bab"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["'''\nAUTOGRADER CELL. DO NOT MODIFY THIS.\n'''\n\nassert torch.allclose(sigmoid(torch.tensor([1.2])), torch.tensor([0.7685]), rtol=1e-2)\nassert torch.allclose(sigmoid(torch.tensor([0, 1.5])), torch.tensor([0.5000, 0.8176]), rtol=1e-2)\n\n"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.635026Z","start_time":"2021-11-09T19:59:53.631133Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f4d85f3-947d-43f4-857c-5878a48f3b08"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-61532367e8d33755","locked":true,"solution":false,"points":10,"checksum":"73c93decc465fa69d9fc774e746b0261","grade":true,"cell_type":"code"},"editable":false},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Exercise 2 [10 points]\n\nImplement a Softmax function on your own.\n\n$$\\mathrm{softmax}(\\mathbf{X})_{ij} = \\frac{\\exp(\\mathbf{X}_{ij})}{\\sum_k \\exp(\\mathbf{X}_{ik})}$$\n\nNote that you should not use existing PyTorch implementation.\n\nHint: try `torch.exp()` and `torch.sum()`."],"metadata":{"ExecuteTime":{"end_time":"2021-06-06T04:38:56.061939Z","start_time":"2021-06-06T04:38:56.056875Z"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"569c8875-963b-4a1f-94e3-1d3a1187cce5"}}},{"cell_type":"code","source":["def softmax(X):\n    # your code here\n    maxes = torch.max(X, 1, keepdim=True)[0]\n    x_exp = torch.exp(X-maxes)\n    x_exp_sum = torch.sum(x_exp, 1, keepdim=True)\n    return x_exp/x_exp_sum\n\n    #raise NotImplementedError"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.643476Z","start_time":"2021-11-09T19:59:53.640913Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea26b754-b0d4-4447-aed8-33d386b05894"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["'''\nAUTOGRADER CELL. DO NOT MODIFY THIS.\n'''\n\nX = torch.tensor([[0.2288, 0.4111, 0.0385], [0.6233, 0.0364, 0.1999]])\nassert torch.allclose(softmax(X), torch.tensor([[0.3304, 0.3965, 0.2731], [0.4523, 0.2515, 0.2962]]), rtol=1e-2)\n\n"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.650574Z","start_time":"2021-11-09T19:59:53.647263Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"285b30c2-3860-48f9-ae24-1805253f6352"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-1180d5dc773f6ff4","locked":true,"solution":false,"points":10,"checksum":"a12bf676b0a1039fff4e8e1dc4b02e01","grade":true,"cell_type":"code"},"editable":false},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Exercise 3 [10 points]\n\nImplement a linear layer.\n\n$$\\mathbf{O} = \\mathbf{X}\\mathbf{W} + \\mathbf{b},$$\n\nwhere $\\mathbf{X}$ is the input feature, $\\mathbf{O}$ is the output feature, $\\mathbf{W}$ and $\\mathbf{b}$ are the weight parameters.\n\nHint: try `torch.matmul()`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8150bcf7-c0b4-4f22-9843-e38a54bb4f61"}}},{"cell_type":"code","source":["def linear(X, W, b):\n    # your code here\n    return torch.matmul(X,W)+b\n    #raise NotImplementedError"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.654881Z","start_time":"2021-11-09T19:59:53.652412Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce2dc57b-3b77-4a15-b913-dc604636f4d6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["'''\nAUTOGRADER CELL. DO NOT MODIFY THIS.\n'''\n\nX = torch.Tensor([[0.1, 0.2, 0.3]])\nW = torch.Tensor([[0.1, 0.2, 0.3]]).T\nb = torch.Tensor([-0.5])\nassert torch.allclose(linear(X, W, b), torch.Tensor([[-0.3600]]), rtol=1e-2)\n\n"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.661152Z","start_time":"2021-11-09T19:59:53.657104Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e2e8f0d-7ae7-46bb-bdce-9300d5f76ee0"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-dd9b62c1e826a245","locked":true,"solution":false,"points":10,"checksum":"9b4d48b4c1d9f69fc5a3d4146cd9afb8","grade":true,"cell_type":"code"},"editable":false},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 2. Loss\n\nWhen presented with some training data, our untrained network is likely not to give the correct answer. Loss function measures the degree of dissimilarity of obtained result to the target value, and it is the loss function that we want to minimize during training. To calculate the loss we make a prediction using the inputs of our given data sample and compare it against the true data label value."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-c4a2c15a6a98abf0","locked":true,"solution":false,"checksum":"c10ec179a54a63dd1e620a09940dff8e","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b8021be-c996-4d28-9cd1-b125c5955f3e"}}},{"cell_type":"markdown","source":["Common loss functions include `nn.MSELoss` (Mean Square Error) for regression tasks, and `nn.NLLLoss` (Negative Log Likelihood) for classification. `nn.CrossEntropyLoss` combines `nn.LogSoftmax` and `nn.NLLLoss`. `nn.BCELoss` is specially designed for binary classification."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-3c98f0acdf811685","locked":true,"solution":false,"checksum":"ccc9aecfe0e75fcaa0601e05038cf1c7","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c867fa12-6830-4122-9fad-a9488bec9199"}}},{"cell_type":"markdown","source":["**Mean Square Error**\n\nThe most popular loss function in regression problems is the squared error. When our prediction for an example $i$ is $\\hat{y}^{(i)}$ and the corresponding true label is ${y}^{(i)}$, the squared error is given by:\n\n$$l^{(i)} = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2.$$\n\nTo measure the quality of a model on the entire dataset of $n$ examples, we simply average (or equivalently, sum) the losses on the training set.\n\n$$L =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}.$$\n\nLet us see how to implement this."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-3634cc3d539441c2","locked":true,"solution":false,"checksum":"bcedcd02ba0d289891ba2accd04ca62e","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9217a6d-47ae-4e3d-9803-a7365b8af414"}}},{"cell_type":"code","source":["def squared_loss(y_hat, y):\n    return ((y_hat - y.reshape(y_hat.shape)) ** 2 / 2).mean()"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.665878Z","start_time":"2021-11-09T19:59:53.663104Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3aad2d4-d204-4636-a669-e054579aee85"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-1df21ca45d9d5c67","locked":true,"solution":false,"checksum":"1d263f5353eca3791687c4edfbb38554","grade":false,"cell_type":"code"},"editable":false},"outputs":[],"execution_count":0},{"cell_type":"code","source":["y_hat = torch.tensor([0.5, 0.8, 0.2])\ny = torch.tensor([1.0, 1.0, 0.0])\nsquared_loss(y_hat, y)"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.672639Z","start_time":"2021-11-09T19:59:53.667991Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f511a59a-b6c0-4d5a-98de-b4a8cb6cb78a"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-7c1fcabfc2ba5a9c","locked":true,"solution":false,"checksum":"9431b23a3b8b17ca865a0a3002d1f80c","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[23]: tensor(0.0550)","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[23]: tensor(0.0550)"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Exercise 4 [10 points]\n\nImplement the cross-entropy loss function on your own.\n\n$$l^{(i)} = - \\sum_{j=1}^q y_j^{(i)} \\log \\hat{y}_j^{(i)},$$\n\n$$L =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}.$$\n\nwhere $\\mathbf{y}^{(i)}$ is a one-hot vector of length $q$, the sum over all its coordinates $j$ vanishes for all but one term.\n\nNote that you should not use existing PyTorch implementation.\n\nHint: try `torch.log()`."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-1cabefeec5e1cf70","locked":true,"solution":false,"checksum":"06ebc855353f3068ef9fb75a914d4980","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"365f3345-3e73-4215-9b25-5342d109ae6c"}}},{"cell_type":"code","source":["def cross_entropy(y_hat, y):\n    # your code here\n    return torch.mean(-torch.sum(y * torch.log(y_hat), 1))\n    #l= torch.sum(y,torch.log(y_hat))\n    #return torch.sum(-torch.sum(y,torch.log(y_hat)))\n\n    #raise NotImplementedError"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.676849Z","start_time":"2021-11-09T19:59:53.674726Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"872ca366-d9c3-4f72-847b-31d4b78f108a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["'''\nAUTOGRADER CELL. DO NOT MODIFY THIS.\n'''\n\ny = torch.tensor([[1, 0, 0], [0, 0, 1]])\ny_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\nassert torch.allclose(cross_entropy(y_hat, y), torch.tensor([1.4979]), rtol=1e-2)\n\n"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.682470Z","start_time":"2021-11-09T19:59:53.678810Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbbc1372-7bcd-4612-b193-0618c4f09a8f"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-c6fed73a25633029","locked":true,"solution":false,"points":10,"checksum":"12f4d9e1cad788bb8e3be9ba16e85017","grade":true,"cell_type":"code"},"editable":false},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 3. Autograd\n\nWhen training the model, we want to find parameters (denoted as $\\Theta$) that minimize the total loss across all training examples:\n\n$$\\Theta = \\operatorname*{argmin}_{\\Theta}\\  L(\\Theta).$$\n\nTo do this, we will iteratively reduce the error by updating the parameters in the direction that incrementally lowers the loss function. This algorithm is called gradient descent. The most naive application of gradient descent consists of taking the derivative of the loss function. Let us see how to do this."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-d2696116d62fd7ca","locked":true,"solution":false,"checksum":"bfb88b78b06ad42c14a5d0f820f88120","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f629391-7b1d-4621-9f8b-05c6a70a413b"}}},{"cell_type":"markdown","source":["As a toy example, say that we are interested in differentiating the function $y = 2 \\mathbf{x}^\\top \\mathbf{x}$ with respect to the column vector $\\mathbf{x}$. To start, let us create the variable x and assign it an initial value."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-205d28575317a39c","locked":true,"solution":false,"checksum":"683eed99a46e6950597f646f7d7f0542","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d36b486-25ee-451f-8e98-0a5e89bfb7ed"}}},{"cell_type":"code","source":["x = torch.arange(4.0)\nx"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.688440Z","start_time":"2021-11-09T19:59:53.684498Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"875123b0-4185-4698-a552-002fd12c8fe6"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-a94c031cf67afb4f","locked":true,"solution":false,"checksum":"831b87d6ad6c21d671885c9b59d4052f","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[26]: tensor([0., 1., 2., 3.])","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[26]: tensor([0., 1., 2., 3.])"]}}],"execution_count":0},{"cell_type":"code","source":["x.requires_grad_(True)  # Same as `x = torch.arange(4.0, requires_grad=True)`\nx.grad  # The default value is None"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.692926Z","start_time":"2021-11-09T19:59:53.690413Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17c224b7-6b48-428a-ad07-103eff3cf915"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-9343288efcab2ee8","locked":true,"solution":false,"checksum":"9ba41fc51c935748a491e81afe5a9cb5","grade":false,"cell_type":"code"},"editable":false},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now let us calculate $y$."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-8f9fe71daeddcdaa","locked":true,"solution":false,"checksum":"38a03324937b683b75c932eda2830925","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2921b654-c7ae-4e3b-980e-43fdb3454f75"}}},{"cell_type":"code","source":["y = 2 * torch.dot(x, x)\ny"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.699730Z","start_time":"2021-11-09T19:59:53.695285Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ad07bb9-e132-4e7f-aaab-68c8163190a1"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-962c853218ef8a99","locked":true,"solution":false,"checksum":"190120bc8195216af556bea10a61d2ba","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[28]: tensor(28., grad_fn=<MulBackward0>)","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[28]: tensor(28., grad_fn=<MulBackward0>)"]}}],"execution_count":0},{"cell_type":"markdown","source":["Since $\\mathbf{x}$ is a vector of length 4, an inner product of $\\mathbf{x}$ and $\\mathbf{x}$ is performed, yielding the scalar output that we assign to $y$. Next, we can automatically calculate the gradient of $y$ with respect to each component of $\\mathbf{x}$ by calling the function for backpropagation and printing the gradient."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-5dd01161ebcf0e5d","locked":true,"solution":false,"checksum":"894f7a758ee313a5b86f56c1d69069f2","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3260f38d-ad7f-41ae-84a0-51c2f34d554e"}}},{"cell_type":"code","source":["y.backward()\nx.grad"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.706397Z","start_time":"2021-11-09T19:59:53.701945Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6157c582-6ca3-401c-a239-da9011ad6ce5"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-d69f7e1a6b657229","locked":true,"solution":false,"checksum":"590e79a7c90c813eecfa9514a7b7b916","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[29]: tensor([ 0.,  4.,  8., 12.])","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[29]: tensor([ 0.,  4.,  8., 12.])"]}}],"execution_count":0},{"cell_type":"markdown","source":["The gradient of the function $y = 2\\mathbf{x}^{\\top}\\mathbf{x}$ with respect to $\\mathbf{x}$ should be $4\\mathbf{x}$. Let us quickly verify that our desired gradient was calculated correctly."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-c9f74064d0da6335","locked":true,"solution":false,"checksum":"b98732384eb41e2190df66b086679f0c","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68185974-c1c4-4b50-9ee8-e9bf1328bf0e"}}},{"cell_type":"code","source":["x.grad == 4 * x"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.712706Z","start_time":"2021-11-09T19:59:53.708310Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db46cdd7-e539-4636-bce9-8c6a0de6430e"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-9ecb119a6399614b","locked":true,"solution":false,"checksum":"98eeddff71971aa7e9d3139bbbf610c1","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[31]: tensor([True, True, True, True])","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[31]: tensor([True, True, True, True])"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Exercise 5 [10 points]\n\nLet  $f(x) = \\sin(x)$. Plot $f(x)$ and and $\\frac{df(x)}{dx}$, where the latter is computed without exploiting that $f'(x) = \\cos(x)$."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-0a368433383bc78c","locked":true,"solution":false,"checksum":"666297b89310b1dd925c3dff70abd221","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ac3312c6-5111-438f-9196-ce4c615237ce"}}},{"cell_type":"code","source":["x = np.linspace(-np.pi, np.pi, 100)\nx = torch.tensor(x, requires_grad=True)\nprint(x)\ny = torch.sin(x)\n# your code here\ny.backward(torch.ones_like(x))\nplt.plot(x.detach().numpy(), y.detach().numpy(), label='sin(x)')\nplt.plot(x.detach().numpy(), x.grad.detach().numpy(), label='cos(x)') # print derivative of sin(x)\nplt.show()\n#raise NotImplementedError"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.904887Z","start_time":"2021-11-09T19:59:53.714715Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38df1a8e-8d8b-407f-97ab-30c8d86f02e6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"tensor([-3.1416, -3.0781, -3.0147, -2.9512, -2.8877, -2.8243, -2.7608, -2.6973,\n        -2.6339, -2.5704, -2.5069, -2.4435, -2.3800, -2.3165, -2.2531, -2.1896,\n        -2.1261, -2.0627, -1.9992, -1.9357, -1.8723, -1.8088, -1.7453, -1.6819,\n        -1.6184, -1.5549, -1.4915, -1.4280, -1.3645, -1.3011, -1.2376, -1.1741,\n        -1.1107, -1.0472, -0.9837, -0.9203, -0.8568, -0.7933, -0.7299, -0.6664,\n        -0.6029, -0.5395, -0.4760, -0.4125, -0.3491, -0.2856, -0.2221, -0.1587,\n        -0.0952, -0.0317,  0.0317,  0.0952,  0.1587,  0.2221,  0.2856,  0.3491,\n         0.4125,  0.4760,  0.5395,  0.6029,  0.6664,  0.7299,  0.7933,  0.8568,\n         0.9203,  0.9837,  1.0472,  1.1107,  1.1741,  1.2376,  1.3011,  1.3645,\n         1.4280,  1.4915,  1.5549,  1.6184,  1.6819,  1.7453,  1.8088,  1.8723,\n         1.9357,  1.9992,  2.0627,  2.1261,  2.1896,  2.2531,  2.3165,  2.3800,\n         2.4435,  2.5069,  2.5704,  2.6339,  2.6973,  2.7608,  2.8243,  2.8877,\n         2.9512,  3.0147,  3.0781,  3.1416], dtype=torch.float64,\n       requires_grad=True)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["tensor([-3.1416, -3.0781, -3.0147, -2.9512, -2.8877, -2.8243, -2.7608, -2.6973,\n        -2.6339, -2.5704, -2.5069, -2.4435, -2.3800, -2.3165, -2.2531, -2.1896,\n        -2.1261, -2.0627, -1.9992, -1.9357, -1.8723, -1.8088, -1.7453, -1.6819,\n        -1.6184, -1.5549, -1.4915, -1.4280, -1.3645, -1.3011, -1.2376, -1.1741,\n        -1.1107, -1.0472, -0.9837, -0.9203, -0.8568, -0.7933, -0.7299, -0.6664,\n        -0.6029, -0.5395, -0.4760, -0.4125, -0.3491, -0.2856, -0.2221, -0.1587,\n        -0.0952, -0.0317,  0.0317,  0.0952,  0.1587,  0.2221,  0.2856,  0.3491,\n         0.4125,  0.4760,  0.5395,  0.6029,  0.6664,  0.7299,  0.7933,  0.8568,\n         0.9203,  0.9837,  1.0472,  1.1107,  1.1741,  1.2376,  1.3011,  1.3645,\n         1.4280,  1.4915,  1.5549,  1.6184,  1.6819,  1.7453,  1.8088,  1.8723,\n         1.9357,  1.9992,  2.0627,  2.1261,  2.1896,  2.2531,  2.3165,  2.3800,\n         2.4435,  2.5069,  2.5704,  2.6339,  2.6973,  2.7608,  2.8243,  2.8877,\n         2.9512,  3.0147,  3.0781,  3.1416], dtype=torch.float64,\n       requires_grad=True)\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"data:image/png;base64,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\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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\n"}}],"execution_count":0},{"cell_type":"code","source":["'''\nAUTOGRADER CELL. DO NOT MODIFY THIS.\n'''\n\nassert torch.allclose(x.grad[10].float(), torch.Tensor([-0.8053]), rtol=1e-2)\nassert torch.allclose(x.grad[50].float(), torch.Tensor([0.9995]), rtol=1e-2)\n\n"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.910186Z","start_time":"2021-11-09T19:59:53.907139Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d981be1b-9822-4983-9f61-e3e48f827720"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-cd0a5df68eb0bdde","locked":true,"solution":false,"points":10,"checksum":"1f269cdf3eec73dc8cc5677f149ae164","grade":true,"cell_type":"code"},"editable":false},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Assignment [50 points]"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-85c2cf25d4fba682","locked":true,"solution":false,"checksum":"b11b0661947ed8e109c225e96ceeea99","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a7adfea-8123-43f8-abf3-f88b832c5562"}}},{"cell_type":"markdown","source":["Now, you understand the basics of PyTorch. Let us implement an entire method from scratch, including the data pipeline, the linear model, the loss function, and the gradient descent optimizer. While modern deep learning frameworks can automate nearly all of this work, implementing things from scratch is the only way to make sure that you really know what you are doing. Moreover, when it comes time to customize models, defining our own layers or loss functions, understanding how things work under the hood will prove handy. In this section, we will rely only on tensors and auto differentiation. Afterwards, we will introduce a more concise implementation, taking advantage of bells and whistles of deep learning frameworks."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-b4a75a8b976d4aaf","locked":true,"solution":false,"checksum":"1b35a9f46a60db8bd30c264b5d9db957","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b53260e7-f3f4-4e3c-94d4-23cd7e18b26f"}}},{"cell_type":"markdown","source":["To keep things simple, we will construct an artificial dataset according to a linear model with additive noise. Our task will be to recover this model’s parameters using the finite set of examples contained in our dataset. We will keep the data low-dimensional so we can visualize it easily. In the following code snippet, we generate a dataset containing 1000 examples, each consisting of 2 features sampled from a standard normal distribution. Thus our synthetic dataset will be a matrix  $\\mathbf{X} \\in \\mathbb{R}^{1000 \\times 2}$.\n\nThe true parameters generating our dataset will be $\\mathbf{w} = [2, -3.4]^\\top$ and  $b = 4.2$, and our synthetic labels will be assigned according to the following linear model with the noise term $\\epsilon$:\n$$\\mathbf{y}= \\mathbf{X} \\mathbf{w} + b + \\mathbf\\epsilon.$$"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-23a60381928f9e78","locked":true,"solution":false,"checksum":"b9a10ff3eed9d4d86486552f7eb8d521","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a39acc6-0ce7-4c08-8dd9-c91dd8f5b864"}}},{"cell_type":"code","source":["def synthetic_data(w, b, num_examples):\n    \"\"\"Generate y = Xw + b + noise.\"\"\"\n    X = torch.normal(0, 1, (num_examples, len(w)))\n    y = torch.matmul(X, w) + b\n    y += torch.normal(0, 0.01, y.shape)\n    return X, y.reshape((-1, 1))\n\ntrue_w = torch.tensor([2, -3.4])\ntrue_b = 4.2\nfeatures, labels = synthetic_data(true_w, true_b, 1000)"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.915810Z","start_time":"2021-11-09T19:59:53.911988Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"907cfd30-38c4-4854-bac0-7316454a44aa"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-ba81e3393eb6f13c","locked":true,"solution":false,"checksum":"eafb54534edc50b5f60ad281bd7905cc","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["print('features:', features[0], '\\nlabel:', labels[0])"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.921422Z","start_time":"2021-11-09T19:59:53.917405Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59b164c9-9dd8-4945-8264-16e4d2e470a3"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-f30d23919c1bc1f4","locked":true,"solution":false,"checksum":"eaaa5b43b7df88198948cc2af18b2a55","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">features: tensor([-0.6953,  0.6804]) \nlabel: tensor([0.4801])\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">features: tensor([-0.6953,  0.6804]) \nlabel: tensor([0.4801])\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Reading the Dataset\n\nRecall that training models consists of making multiple passes over the dataset, grabbing one minibatch of examples at a time, and using them to update our model. Since this process is so fundamental to training machine learning algorithms, it is worth defining a utility function to shuffle the dataset and access it in minibatches.\n\nIn the following code, we define the `data_iter` function to demonstrate one possible implementation of this functionality. The function takes a batch size, a matrix of features, and a vector of labels, yielding minibatches of the size batch_size. Each minibatch consists of a tuple of features and labels."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-ff3a9ba26f232db9","locked":true,"solution":false,"checksum":"b64abf8de56dce8792e40c54623f330c","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee4ac324-3452-4c45-8ddb-db26ddea32e4"}}},{"cell_type":"code","source":["def data_iter(batch_size, features, labels):\n    num_examples = len(features)\n    indices = list(range(num_examples))\n    # The examples are read at random, in no particular order\n    random.shuffle(indices)\n    for i in range(0, num_examples, batch_size):\n        batch_indices = torch.tensor(indices[i:min(i + batch_size, num_examples)])\n        yield features[batch_indices], labels[batch_indices]"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.926672Z","start_time":"2021-11-09T19:59:53.923342Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae966786-2ae9-4677-9d36-a9f03f3d9862"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-62ff69e249c9f591","locked":true,"solution":false,"checksum":"7174ddcb46bd3dde2a46f2e6a4c805b0","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["In general, note that we want to use reasonably sized minibatches to take advantage of the GPU hardware, which excels at parallelizing operations. Because each example can be fed through our models in parallel and the gradient of the loss function for each example can also be taken in parallel, GPUs allow us to process hundreds of examples in scarcely more time than it might take to process just a single example.\n\nTo build some intuition, let us read and print the first small batch of data examples. The shape of the features in each minibatch tells us both the minibatch size and the number of input features. Likewise, our minibatch of labels will have a shape given by batch_size."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-e9a6a7834942b2ad","locked":true,"solution":false,"checksum":"723d6edc8c2290eab86d5db0bae4b4cc","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9047b0c2-c4fb-4d45-adac-77b3304ce798"}}},{"cell_type":"code","source":["batch_size = 10\n\nfor X, y in data_iter(batch_size, features, labels):\n    print(X, '\\n', y)\n    break"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.932958Z","start_time":"2021-11-09T19:59:53.928327Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4f8ae33-0869-4bca-892d-48285bf5fd9f"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-07e5479f42cdbff4","locked":true,"solution":false,"checksum":"5db45991e3570242e92bc0985ace3250","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">tensor([[ 1.2861, -0.4764],\n        [-1.6240,  0.0993],\n        [ 0.0708, -2.3352],\n        [-0.1933, -0.9653],\n        [-1.1281, -0.5231],\n        [-0.0888, -0.0762],\n        [-0.1606,  1.8809],\n        [ 1.7079, -0.7779],\n        [-1.4014,  0.7466],\n        [ 0.0190, -0.2504]]) \n tensor([[ 8.3947],\n        [ 0.6248],\n        [12.2746],\n        [ 7.1153],\n        [ 3.7129],\n        [ 4.2675],\n        [-2.5028],\n        [10.2504],\n        [-1.1474],\n        [ 5.0797]])\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">tensor([[ 1.2861, -0.4764],\n        [-1.6240,  0.0993],\n        [ 0.0708, -2.3352],\n        [-0.1933, -0.9653],\n        [-1.1281, -0.5231],\n        [-0.0888, -0.0762],\n        [-0.1606,  1.8809],\n        [ 1.7079, -0.7779],\n        [-1.4014,  0.7466],\n        [ 0.0190, -0.2504]]) \n tensor([[ 8.3947],\n        [ 0.6248],\n        [12.2746],\n        [ 7.1153],\n        [ 3.7129],\n        [ 4.2675],\n        [-2.5028],\n        [10.2504],\n        [-1.1474],\n        [ 5.0797]])\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["As we run the iteration, we obtain distinct minibatches successively until the entire dataset has been exhausted (try this). While the iteration implemented above is good for didactic purposes, it is inefficient in ways that might get us in trouble on real problems. For example, it requires that we load all the data in memory and that we perform lots of random memory access. The built-in iterators implemented in a deep learning framework are considerably more efficient and they can deal with both data stored in files and data fed via data streams."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-e1249e2768b4a70b","locked":true,"solution":false,"checksum":"61ba9fba2d0b02868875ce1b7ab0f8a2","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c4a4fa63-e3cf-4558-9ae8-3a9a860302eb"}}},{"cell_type":"markdown","source":["### Initializing Model Parameters [10 points]\n\nBefore we can begin optimizing our model’s parameters by minibatch stochastic gradient descent, we need to have some parameters in the first place. In the following code, we initialize weights by sampling random numbers from a normal distribution with mean 0 and a standard deviation of 0.01, and setting the bias to 0."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-8a4bb6bb84c24d82","locked":true,"solution":false,"checksum":"04f16441b25d0c7c21425a3c3c10ed43","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c249e7a-e837-4700-a733-430811b7a331"}}},{"cell_type":"code","source":["import  torch.nn as nn, seaborn as sns\nw = None\nb = None\n# your code here\nw = nn.Linear(100, 100)\nnn.init.normal_(w.weight, mean=0, std=0.01)\nnn.init.constant_(w.bias.data,0)\nb=w(torch.zeros(100))\nw = w(torch.rand(100))\nprint(w)\n#b=torch.zeros(100)\n#b.grad\n#sns.distplot(w.weight.detach().numpy())\n#raise NotImplementedError"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.936969Z","start_time":"2021-11-09T19:59:53.934449Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":true,"inputWidgets":{},"nuid":"14649e64-0ad8-4932-888f-9b86d3b3a971"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">tensor([ 0.0668, -0.0256,  0.0274, -0.0015,  0.0095,  0.0055, -0.0577, -0.0012,\n         0.0551,  0.0260,  0.0077,  0.0483, -0.0380,  0.0375,  0.0325,  0.0345,\n         0.0590,  0.0672,  0.0423,  0.0349, -0.0288,  0.0141, -0.0032,  0.0248,\n         0.0322, -0.0401, -0.0206, -0.0453,  0.0330,  0.0039, -0.0237,  0.0687,\n        -0.0365, -0.1214, -0.0168,  0.0493, -0.1047,  0.1192,  0.1002,  0.0607,\n        -0.0323, -0.0489,  0.0276,  0.0221,  0.0393, -0.1586,  0.0338, -0.0211,\n         0.0385, -0.0638,  0.0652, -0.0675, -0.0193,  0.0020,  0.0012, -0.0189,\n        -0.0213,  0.0036, -0.0250,  0.0178, -0.0298, -0.0520,  0.0242, -0.0410,\n        -0.0360,  0.0767, -0.0217, -0.0140, -0.0022,  0.0402,  0.0066,  0.0259,\n         0.0090, -0.0764,  0.0575, -0.0436,  0.0857, -0.0317, -0.0055, -0.0725,\n        -0.0677, -0.0057, -0.0206,  0.0075,  0.0272, -0.0812, -0.0207,  0.1434,\n         0.0007, -0.0443,  0.0265, -0.0778,  0.0274,  0.0696, -0.0199, -0.0480,\n         0.0211, -0.0200,  0.0671,  0.1204], grad_fn=&lt;AddBackward0&gt;)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">tensor([ 0.0668, -0.0256,  0.0274, -0.0015,  0.0095,  0.0055, -0.0577, -0.0012,\n         0.0551,  0.0260,  0.0077,  0.0483, -0.0380,  0.0375,  0.0325,  0.0345,\n         0.0590,  0.0672,  0.0423,  0.0349, -0.0288,  0.0141, -0.0032,  0.0248,\n         0.0322, -0.0401, -0.0206, -0.0453,  0.0330,  0.0039, -0.0237,  0.0687,\n        -0.0365, -0.1214, -0.0168,  0.0493, -0.1047,  0.1192,  0.1002,  0.0607,\n        -0.0323, -0.0489,  0.0276,  0.0221,  0.0393, -0.1586,  0.0338, -0.0211,\n         0.0385, -0.0638,  0.0652, -0.0675, -0.0193,  0.0020,  0.0012, -0.0189,\n        -0.0213,  0.0036, -0.0250,  0.0178, -0.0298, -0.0520,  0.0242, -0.0410,\n        -0.0360,  0.0767, -0.0217, -0.0140, -0.0022,  0.0402,  0.0066,  0.0259,\n         0.0090, -0.0764,  0.0575, -0.0436,  0.0857, -0.0317, -0.0055, -0.0725,\n        -0.0677, -0.0057, -0.0206,  0.0075,  0.0272, -0.0812, -0.0207,  0.1434,\n         0.0007, -0.0443,  0.0265, -0.0778,  0.0274,  0.0696, -0.0199, -0.0480,\n         0.0211, -0.0200,  0.0671,  0.1204], grad_fn=&lt;AddBackward0&gt;)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["'''\nAUTOGRADER CELL. DO NOT MODIFY THIS.\n'''\n\nassert type(w) is torch.Tensor\nassert type(b) is torch.Tensor\nassert w.requires_grad\nassert b.requires_grad\n\n"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.942141Z","start_time":"2021-11-09T19:59:53.939098Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80176090-a7e4-4fb5-985d-3b1bb151e004"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-ce0ca0f090c01ba9","locked":true,"solution":false,"points":10,"checksum":"f478d9b29249623cfa6a66c6720fcff9","grade":true,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Defining the Model [10 points]\n\nNext, we must define our model, relating its inputs and parameters to its outputs. Recall that to calculate the output of the linear model, we simply take the matrix-vector dot product of the input features $\\mathbf{x}$ and the model weights $\\mathbf{w}$ , and add the offset $b$ to each example.\n\nThis is exactly the same as what we implemented in Exercise 3."],"metadata":{"ExecuteTime":{"end_time":"2021-06-06T07:51:46.589522Z","start_time":"2021-06-06T07:51:46.586432Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a8d84f59-150b-4fe6-8023-ef5618e1ed9c"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-615d1fb813fa002a","locked":true,"solution":false,"checksum":"fcaab39d8614129a614e410c39aa75cf","grade":false,"cell_type":"markdown"},"editable":false}},{"cell_type":"code","source":["def linear(X, W, b):\n    # your code here\n    return torch.matmul(X,W)+b\n    #raise NotImplementedError"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.946691Z","start_time":"2021-11-09T19:59:53.944101Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f14cb93-381b-44fa-b679-551e4daa8a3f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["'''\nAUTOGRADER CELL. DO NOT MODIFY THIS.\n'''\n\nX_ = torch.Tensor([[0.1, 0.2, 0.3]])\nW_ = torch.Tensor([[0.1, 0.2, 0.3]]).T\nb_ = torch.Tensor([-0.5])\nassert torch.allclose(linear(X_, W_, b_), torch.Tensor([[-0.3600]]), rtol=1e-2)\n\n"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.952489Z","start_time":"2021-11-09T19:59:53.948582Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82097a4a-2f38-4eeb-afcb-647089820101"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-64c3079cc937f819","locked":true,"solution":false,"points":10,"checksum":"30c488519d52ee094de4ce5f15452ec3","grade":true,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Defining the Loss Function [10 points]\n\nSince updating our model requires taking the gradient of our loss function, we ought to define the loss function first. Here we will use the squared loss function."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-9a215192ecde9028","locked":true,"solution":false,"checksum":"596694b9faa75514f1c038f7ff8bfa38","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"475fa3e5-79d7-4ea6-83ac-905c368e48c0"}}},{"cell_type":"code","source":["def squared_loss(y_hat, y):\n    # your code here\n    mse_loss = nn.MSELoss()\n    return mse_loss(y,y_hat)\n    #raise NotImplementedError"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.957811Z","start_time":"2021-11-09T19:59:53.954638Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdefcbeb-ba77-44a9-8c9a-4ddc00738db0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["y = torch.tensor([2, 0.4, 1.1, 2.1])\ny_hat = torch.tensor([[2.1, 0.3, 1.2, 2.5]])\nmse_loss = nn.MSELoss()\nmse_loss(y, y_hat)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bef64d28-5a58-4a9d-86d1-4d4521711a82"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[64]: tensor(0.0475)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[64]: tensor(0.0475)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["'''\nAUTOGRADER CELL. DO NOT MODIFY THIS.\n'''\n\ny = torch.tensor([2, 0.4, 1.1, 2.1])\ny_hat = torch.tensor([[2.1, 0.3, 1.2, 2.3]])\nassert torch.allclose(squared_loss(y_hat, y), torch.tensor([0.0238]), rtol=1e-2)\n\n"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.963766Z","start_time":"2021-11-09T19:59:53.959848Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"beb0bcf9-14fe-4d4b-9045-5ff3527b51ed"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-c736aba0ee97c23a","locked":true,"solution":false,"points":10,"checksum":"5ea08d374ccf94632a06bf43e9ca6198","grade":true,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AssertionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-320279718370938&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> y <span class=\"ansi-blue-fg\">=</span> torch<span class=\"ansi-blue-fg\">.</span>tensor<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">0.4</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1.1</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">2.1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> y_hat <span class=\"ansi-blue-fg\">=</span> torch<span class=\"ansi-blue-fg\">.</span>tensor<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2.1</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">0.3</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1.2</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">2.3</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 7</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">assert</span> torch<span class=\"ansi-blue-fg\">.</span>allclose<span class=\"ansi-blue-fg\">(</span>squared_loss<span class=\"ansi-blue-fg\">(</span>y_hat<span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> torch<span class=\"ansi-blue-fg\">.</span>tensor<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0.0238</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> rtol<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1e-2</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> \n\n<span class=\"ansi-red-fg\">AssertionError</span>: </div>","errorSummary":"<span class=\"ansi-red-fg\">AssertionError</span>: ","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AssertionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-320279718370938&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> y <span class=\"ansi-blue-fg\">=</span> torch<span class=\"ansi-blue-fg\">.</span>tensor<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">0.4</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1.1</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">2.1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> y_hat <span class=\"ansi-blue-fg\">=</span> torch<span class=\"ansi-blue-fg\">.</span>tensor<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2.1</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">0.3</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1.2</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">2.3</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 7</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">assert</span> torch<span class=\"ansi-blue-fg\">.</span>allclose<span class=\"ansi-blue-fg\">(</span>squared_loss<span class=\"ansi-blue-fg\">(</span>y_hat<span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> torch<span class=\"ansi-blue-fg\">.</span>tensor<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0.0238</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> rtol<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1e-2</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> \n\n<span class=\"ansi-red-fg\">AssertionError</span>: </div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Defining the Optimization Algorithm [10 points]\n\nThough linear regression has a closed-form solution, we will take this opportunity to introduce your first working example of minibatch stochastic gradient descent.\n\nAt each step, using one minibatch randomly drawn from our dataset, we will estimate the gradient of the loss with respect to our parameters. Next, we will update our parameters in the direction that may reduce the loss. The following code applies the minibatch stochastic gradient descent update, given a set of parameters, a learning rate, and a batch size. The size of the update step is determined by the learning rate lr. Because our loss is calculated as a sum over the minibatch of examples, we normalize our step size by the batch size (batch_size), so that the magnitude of a typical step size does not depend heavily on our choice of the batch size."],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-6cfd21d340b940b9","locked":true,"solution":false,"checksum":"6206504a7d0da08b5515310a3b285534","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20de1bbc-0c19-4a66-b366-1aedfbfe1f62"}}},{"cell_type":"code","source":["def sgd(params, lr, batch_size):\n    \"\"\"  Minibatch stochastic gradient descent \"\"\"\n    lr = lr / batch_size\n    with torch.no_grad():\n        for param in params:\n            \"\"\"\n            TODO: perform a step gradient descent \n                  param = param - lr * grad\n            \"\"\"\n            # your code here\n            \n            #raise NotImplementedError\n            param.grad.zero_()\n            param = param - lr * param.grad"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.968307Z","start_time":"2021-11-09T19:59:53.965629Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e052867-ea8f-4653-946d-0b95247adb15"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["'''\nAUTOGRADER CELL. DO NOT MODIFY THIS.\n'''\n\nm = torch.ones(1, requires_grad=True)\nn = 2 * m\nn.backward()\nsgd([m], lr=0.1, batch_size=1)\nassert torch.allclose(m, torch.tensor([0.8000]), rtol=1e-2)\n\n"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:53.974039Z","start_time":"2021-11-09T19:59:53.970317Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cdb12e30-16de-4ac1-a03b-7337b1afe9b5"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-fc34af6a3ad58767","locked":true,"solution":false,"points":10,"checksum":"3194a739ec2f40960d06c5b3826719ed","grade":true,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AssertionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-320279718370941&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> n<span class=\"ansi-blue-fg\">.</span>backward<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> sgd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span>m<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> lr<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">0.1</span><span class=\"ansi-blue-fg\">,</span> batch_size<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 9</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">assert</span> torch<span class=\"ansi-blue-fg\">.</span>allclose<span class=\"ansi-blue-fg\">(</span>m<span class=\"ansi-blue-fg\">,</span> torch<span class=\"ansi-blue-fg\">.</span>tensor<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0.8000</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> rtol<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1e-2</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span> \n\n<span class=\"ansi-red-fg\">AssertionError</span>: </div>","errorSummary":"<span class=\"ansi-red-fg\">AssertionError</span>: ","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AssertionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-320279718370941&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> n<span class=\"ansi-blue-fg\">.</span>backward<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      8</span> sgd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span>m<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> lr<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">0.1</span><span class=\"ansi-blue-fg\">,</span> batch_size<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 9</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-green-fg\">assert</span> torch<span class=\"ansi-blue-fg\">.</span>allclose<span class=\"ansi-blue-fg\">(</span>m<span class=\"ansi-blue-fg\">,</span> torch<span class=\"ansi-blue-fg\">.</span>tensor<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0.8000</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> rtol<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1e-2</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span> \n\n<span class=\"ansi-red-fg\">AssertionError</span>: </div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Training [10 points]\n\nNow that we have all of the parts in place, we are ready to implement the main training loop. It is crucial that you understand this code because you will see nearly identical training loops over and over again throughout your career in deep learning.\n\nIn each iteration, we will grab a minibatch of training examples, and pass them through our model to obtain a set of predictions. After calculating the loss, we initiate the backwards pass through the network, storing the gradients with respect to each parameter. Finally, we will call the optimization algorithm sgd to update the model parameters.\n\nIn summary, we will execute the following loop:"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-b1f4936a88b7fc46","locked":true,"solution":false,"checksum":"17670b2bf4bdadb6fba07d4d0a2ab68e","grade":false,"cell_type":"markdown"},"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7817ce0-4814-4a4b-8850-f54e991c5255"}}},{"cell_type":"code","source":["lr = 0.03\nnum_epochs = 20\nnet = linear\nloss = squared_loss\n\nfor epoch in range(num_epochs):\n    for X, y in data_iter(batch_size, features, labels):\n        l = loss(net(X, w, b), y)  # Minibatch loss in `X` and `y`\n        # Compute gradient on `l` with respect to [`w`, `b`]\n        l.backward()\n        sgd([w, b], lr, batch_size)  # Update parameters using their gradient\n    with torch.no_grad():\n        train_l = loss(net(features, w, b), labels)\n        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:54.493522Z","start_time":"2021-11-09T19:59:53.975739Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de740a22-2884-4cdf-bf81-10fd79a7d671"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-f5bcc835498528f7","locked":true,"solution":false,"checksum":"5fea51198b0914c1df9789dd019d22d2","grade":false,"cell_type":"code"},"editable":false},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">RuntimeError</span>                              Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-320279718370943&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> <span class=\"ansi-green-fg\">for</span> epoch <span class=\"ansi-green-fg\">in</span> range<span class=\"ansi-blue-fg\">(</span>num_epochs<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span>     <span class=\"ansi-green-fg\">for</span> X<span class=\"ansi-blue-fg\">,</span> y <span class=\"ansi-green-fg\">in</span> data_iter<span class=\"ansi-blue-fg\">(</span>batch_size<span class=\"ansi-blue-fg\">,</span> features<span class=\"ansi-blue-fg\">,</span> labels<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">----&gt; 8</span><span class=\"ansi-red-fg\">         </span>l <span class=\"ansi-blue-fg\">=</span> loss<span class=\"ansi-blue-fg\">(</span>net<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> w<span class=\"ansi-blue-fg\">,</span> b<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">)</span>  <span class=\"ansi-red-fg\"># Minibatch loss in `X` and `y`</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      9</span>         <span class=\"ansi-red-fg\"># Compute gradient on `l` with respect to [`w`, `b`]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span>         l<span class=\"ansi-blue-fg\">.</span>backward<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;command-320279718370934&gt;</span> in <span class=\"ansi-cyan-fg\">linear</span><span class=\"ansi-blue-fg\">(X, W, b)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">def</span> linear<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> W<span class=\"ansi-blue-fg\">,</span> b<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>     <span class=\"ansi-red-fg\"># your code here</span>\n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> torch<span class=\"ansi-blue-fg\">.</span>matmul<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span>W<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">+</span>b\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>     <span class=\"ansi-red-fg\">#raise NotImplementedError</span>\n\n<span class=\"ansi-red-fg\">RuntimeError</span>: size mismatch, got 10, 10x2,100</div>","errorSummary":"<span class=\"ansi-red-fg\">RuntimeError</span>: size mismatch, got 10, 10x2,100","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">RuntimeError</span>                              Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-320279718370943&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> <span class=\"ansi-green-fg\">for</span> epoch <span class=\"ansi-green-fg\">in</span> range<span class=\"ansi-blue-fg\">(</span>num_epochs<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span>     <span class=\"ansi-green-fg\">for</span> X<span class=\"ansi-blue-fg\">,</span> y <span class=\"ansi-green-fg\">in</span> data_iter<span class=\"ansi-blue-fg\">(</span>batch_size<span class=\"ansi-blue-fg\">,</span> features<span class=\"ansi-blue-fg\">,</span> labels<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">----&gt; 8</span><span class=\"ansi-red-fg\">         </span>l <span class=\"ansi-blue-fg\">=</span> loss<span class=\"ansi-blue-fg\">(</span>net<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> w<span class=\"ansi-blue-fg\">,</span> b<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> y<span class=\"ansi-blue-fg\">)</span>  <span class=\"ansi-red-fg\"># Minibatch loss in `X` and `y`</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      9</span>         <span class=\"ansi-red-fg\"># Compute gradient on `l` with respect to [`w`, `b`]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span>         l<span class=\"ansi-blue-fg\">.</span>backward<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;command-320279718370934&gt;</span> in <span class=\"ansi-cyan-fg\">linear</span><span class=\"ansi-blue-fg\">(X, W, b)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-green-fg\">def</span> linear<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span> W<span class=\"ansi-blue-fg\">,</span> b<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span>     <span class=\"ansi-red-fg\"># your code here</span>\n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\">     </span><span class=\"ansi-green-fg\">return</span> torch<span class=\"ansi-blue-fg\">.</span>matmul<span class=\"ansi-blue-fg\">(</span>X<span class=\"ansi-blue-fg\">,</span>W<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">+</span>b\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>     <span class=\"ansi-red-fg\">#raise NotImplementedError</span>\n\n<span class=\"ansi-red-fg\">RuntimeError</span>: size mismatch, got 10, 10x2,100</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(f'error in estimating w: {true_w - w.reshape(true_w.shape)}')\nprint(f'error in estimating b: {true_b - b}')"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:54.499122Z","start_time":"2021-11-09T19:59:54.495321Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee58c417-1184-4aac-a504-755eb3d6e3cc"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-82cd66ab962439d4","locked":true,"solution":false,"checksum":"6715b05b7464b62f52535dc419cb710d","grade":false,"cell_type":"code"},"editable":false},"outputs":[],"execution_count":0},{"cell_type":"code","source":["'''\nAUTOGRADER CELL. DO NOT MODIFY THIS.\n'''\n\nassert (true_w - w.reshape(true_w.shape)).abs().mean() < 0.05\nassert (true_b - b).abs() < 0.05\n\n"],"metadata":{"ExecuteTime":{"end_time":"2021-11-09T19:59:54.503602Z","start_time":"2021-11-09T19:59:54.500685Z"},"deletable":false,"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56423bac-69a3-48ac-8b66-426092e4b62f"},"nbgrader":{"task":false,"schema_version":3,"grade_id":"cell-71658d76dbe33cf9","locked":true,"solution":false,"points":10,"checksum":"f5b9cfab2d884e13c242cfd9a06fc3fa","grade":true,"cell_type":"code"},"editable":false},"outputs":[],"execution_count":0}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.12","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (Threads: 2)","language":"python","name":"python3"},"application/vnd.databricks.v1+notebook":{"notebookName":"LAB1","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":320279718370859},"toc":{"title_sidebar":"Contents","nav_menu":{},"sideBar":true,"number_sections":false,"skip_h1_title":true,"base_numbering":1,"toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"300.390625px"},"toc_section_display":true,"toc_window_display":true,"title_cell":"Table of Contents"},"illinois_payload":{"b64z":"","nb_path":"release/LAB1/LAB1.ipynb"}},"nbformat":4,"nbformat_minor":0}
